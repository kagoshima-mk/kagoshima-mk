# ChatGPT(GTP-3)のここがすごいぞ

## 人の言葉が通じる！

ChatGPTは複雑な自然言語による命令を受け付けることができます。
従来の「コンピュータは決まりきった命令しか受け付けない」という常識は過去のものになりそうです。

これまでデジタルから取り残されていた層にもリーチできるようになります。

## 大規模なデータがなくてもまともに動く！

GPTはGenerative **Pre-trained** Transformerの略です。「Pre-trained」を日本語でいうと事前学習です。

従来の機械学習では「大量のデータがないと十分な精度を出すのは難しい」という課題がありました。
しかしGPTによって「とんでもない規模の大量データで言葉を学習させれば、その後の最適化は少量の学習データでよいし、
なんなら応用力も身につく」というブレイクスルーが起きました。

例えるなら、義務教育をしっかりやっていればその後の仕事の飲み込みもスムーズに行く、というようなものです。

何万件もの学習データを用意しなくても、少量の例を与える(Few-shot Learning)だけで驚くほど精度が上がり、
何なら例を与えなくても(Zero-shot learning)それなりに良い動きをします。

## 学習データと計算量が増えればそれだけ賢くなるらしい！

GPTなどの大規模言語モデル(LLM)の能力はこれからしばらく[学習データとパラメータ数と計算量のべき乗に比例](https://deeplearning.hatenablog.com/entry/scaling_law)し、
その限界も今のところ見えていないそうです。(諸説あるそうですが)

現時点で「さすがにこれは無理かぁ」と諦めたタスクも数カ月後には可能になっている可能性があります。
